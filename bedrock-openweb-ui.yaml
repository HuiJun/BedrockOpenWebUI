services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    pull_policy: always
    container_name: open-webui
    restart: unless-stopped
    ports:
      - ${OPENWEBUI_PORT:-8080}:${OPENWEBUI_PORT:-8080}
    expose:
      - ${OPENWEBUI_PORT:-8080}
    volumes:
      - open-webui:/app/backend/data
    environment:
      - OPENAI_API_BASE_URL=http://bedrock-access-gateway/api/v1
      - OPENAI_API_KEY=bedrock
      - ENABLE_OLLAMA_API=True
      - OLLAMA_BASE_URL=http://ollama-server:11434
      - USE_CUDA_DOCKER=True
      - MODELS_CACHE_TTL=1210000
      - PORT=${OPENWEBUI_PORT:-8080}
    networks:
      - proxy

  bedrock-access-gateway:
    build:
      context: https://github.com/aws-samples/bedrock-access-gateway.git#main:src
      dockerfile: Dockerfile_ecs
    container_name: bedrock-access-gateway
    restart: unless-stopped
    ports:
      - ${BEDROCK_ACCESS_GATEWAY_PORT:-8000}:80
    expose:
      - ${BEDROCK_ACCESS_GATEWAY_PORT:-8000}
    environment:
      - AWS_REGION=${AWS_REGION:-us-west-2}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    networks:
      - proxy

  ollama-server:
    image: ollama/ollama:latest
    pull_policy: always
    volumes:
      - ollama:/root/.ollama
      - ./scripts/ollama/entrypoint.sh:/entrypoint.sh
    container_name: ollama-server
    tty: true
    restart: unless-stopped
    ports:
      - ${OLLAMA_WEBAPI_PORT:-11434}:${OLLAMA_WEBAPI_PORT:-11434}
    expose:
      - ${OLLAMA_WEBAPI_PORT:-11434}
    environment:
      - OLLAMA_WEBAPI_PORT=${OLLAMA_WEBAPI_PORT:-11434}
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    networks:
      - proxy

networks:
  proxy:
    name: open-webui-proxy
    driver: bridge

volumes:
  ollama: {}
  open-webui: {}
