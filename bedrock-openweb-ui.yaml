services:
  traefik:
    image: "traefik:v3.5"
    container_name: "traefik"
    command:
      - "--configfile=/etc/traefik/traefik.yml"
    networks:
      - open-webui-bridge
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - "./assets/certificates:/certificates"
      - "./assets/traefik/traefik.yml:/etc/traefik/traefik.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"

  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    pull_policy: always
    restart: unless-stopped
    command: ["bash", "pre-start.sh"]
    volumes:
      - open-webui:/app/backend/data
      - ./assets/openwebui/pre-start.sh:/app/backend/pre-start.sh
    networks:
      - open-webui-bridge
    environment:
      - PROFILE=${PROFILE}
      - PORT=${OPENWEBUI_PORT:-8080}
      - HOST=0.0.0.0
      - USE_CUDA_DOCKER=True
      - MODELS_CACHE_TTL=1210000
      - ENABLE_FORWARD_USER_INFO_HEADERS=True
      - BYPASS_EMBEDDING_AND_RETRIEVAL=${BYPASS_EMBEDDING_AND_RETRIEVAL:-True}
      - LOCAL_MODEL=${LOCAL_MODEL:-gpt-oss-120b}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASS=${POSTGRES_PASS:-secret}
      - POSTGRES_SERVER=${POSTGRES_SERVER:-pgvector-server}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.webui.rule=PathPrefix(`/`)"
      - "traefik.http.routers.webui.entrypoints=websecure"
      - "traefik.http.routers.webui.tls=true"
      - "traefik.http.routers.webui.tls.certresolver=myresolver"
      - "traefik.http.services.webui.loadbalancer.server.port=8080"

  litellm-server:
    container_name: litellm-server
    image: ghcr.io/berriai/litellm:main-stable
    volumes:
      - ./assets/litellm/config-${LITELLM_MODELS:-bedrock}.yaml:/app/config.yaml
    restart: unless-stopped
    command: ["--config", "/app/config.yaml"]
    networks:
      - open-webui-bridge
    environment:
      - PORT=4000
      - SERVER_ROOT_PATH=/litellm
      - PROXY_BASE_URL=https://localhost
      - UI_BASE_PATH=/litellm/ui
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-1234}
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASS:-secret}@${POSTGRES_SERVER:-pgvector-server}:${POSTGRES_PORT:-5432}/${LITELLM_POSTGRES_DB:-litellm}
      - REDIS_HOST=valkey-server
      - REDIS_PORT=6379
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-west-2}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - AZURE_TENANT_ID=${AZURE_TENANT_ID}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - APIM_SUBSCRIPTION_KEY=${APIM_SUBSCRIPTION_KEY}
      - AZURE_API_BASE=${AZURE_API_BASE}
      - AZURE_API_VERSION=${AZURE_API_VERSION}
      - OLLAMA_API_BASE=http://ollama-server:${OLLAMA_WEBAPI_PORT:-11434}
    profiles:
      - full
      - lite
      - bedrock
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.litellm.rule=PathPrefix(`/litellm`)"
      - "traefik.http.routers.litellm.entrypoints=websecure"
      - "traefik.http.routers.litellm.tls=true"
      - "traefik.http.services.litellm.loadbalancer.server.port=4000"

  ollama-server:
    container_name: ollama-server
    image: ollama/ollama:latest
    pull_policy: always
    entrypoint: [ "/bin/bash", "/entrypoint.sh" ]
    tty: true
    restart: unless-stopped
    volumes:
      - ollama:/root/.ollama
      - ./assets/ollama/entrypoint.sh:/entrypoint.sh
    networks:
      - open-webui-bridge
    environment:
      - OLLAMA_WEBAPI_PORT=${OLLAMA_WEBAPI_PORT:-11434}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LOCAL_MODEL=${LOCAL_MODEL:-hf.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF:Q8_0}
    profiles:
      - full
      - ollama

  searxng-server:
    container_name: searxng-server
    image: ghcr.io/searxng/searxng:latest
    restart: unless-stopped
    networks:
      - open-webui-bridge
    volumes:
      - searxng:/var/cache/searxng
      - ./assets/searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=https://searxng-server:8888/
      - SEARXNG_SECRET=somesearxngsecret
      - SEARXNG_LIMITER=False
      - SEARXNG_PUBLIC_INSTANCE=False
      - GRANIAN_PORT=8888
    profiles:
      - full
      - bedrock
      - ollama

  tika-server:
    image: apache/tika:latest-full
    container_name: tika-server
    restart: unless-stopped
    networks:
      - open-webui-bridge
    profiles:
      - full
      - bedrock
      - ollama

  kokoro-server:
    image: ghcr.io/remsky/kokoro-fastapi-cpu
    container_name: kokoro-server
    restart: always
    networks:
      - open-webui-bridge
    expose:
      - 8880
    profiles:
      - full
      - bedrock
      - ollama

  pgvector-server:
    container_name: pgvector-server
    image: pgvector/pgvector:0.8.0-pg17
    restart: unless-stopped
    volumes:
      - pgvector:/var/lib/postgresql/data
      - ./assets/pgvector/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - open-webui-bridge
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASS:-secret}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-openwebui}
    profiles:
      - full
      - bedrock
      - ollama

  valkey-server:
    container_name: valkey-server
    image: valkey/valkey:8-alpine
    command: valkey-server --save 30 1 --loglevel warning
    restart: unless-stopped
    volumes:
      - valkey:/data
    networks:
      - open-webui-bridge
    profiles:
      - full
      - bedrock
      - ollama

networks:
  open-webui-bridge:
    name: open-webui-bridge
    driver: bridge

volumes:
  ollama:
    labels:
      - "com.github.bedrockopenwebui.stack"
  open-webui:
    labels:
      - "com.github.bedrockopenwebui.stack"
  valkey:
    labels:
      - "com.github.bedrockopenwebui.stack"
  pgvector:
    labels:
      - "com.github.bedrockopenwebui.stack"
  searxng:
    labels:
      - "com.github.bedrockopenwebui.stack"
